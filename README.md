# Part-2-Language-Modeling-Classification

Based on the provided execution results:

SVM Model:

Achieved perfect accuracy and F1 score of 1.0 across all sentiment categories (Irrelevant, Negative, Neutral, Positive).
The classification report shows perfect precision, recall, and F1-score for all sentiment categories.
This indicates that the SVM model performed exceptionally well on the classification task, correctly classifying all instances in the test dataset.
Naive Bayes Model:

Similar to the SVM model, the Naive Bayes model also achieved perfect accuracy and F1 score of 1.0 across all sentiment categories.
The classification report shows perfect precision, recall, and F1-score for all sentiment categories.
This suggests that the Naive Bayes model also performed exceptionally well and was able to classify all instances correctly.
Summary:
Both the SVM and Naive Bayes models achieved outstanding performance on the sentiment classification task, demonstrating perfect accuracy and F1 scores across all sentiment categories. This indicates that the models were able to effectively learn and generalize from the training data to accurately classify tweets into relevant sentiment categories.

Synthesis:
In this Part 2 of the project, we focused on language modeling and sentiment classification using the Twitter Entity Sentiment Analysis dataset. By employing preprocessing techniques such as tokenization, stemming, and stop word removal, we prepared the text data for modeling. We then encoded the data vectors using Word2Vec, Bag of Words, and TF-IDF representations. Training four classification algorithms - SVM, Naive Bayes, Logistic Regression, and AdaBoost - we observed exceptional performance from both SVM and Naive Bayes models, achieving perfect accuracy and F1 scores on sentiment classification. This successful outcome underscores the effectiveness of these models in accurately classifying sentiment in Twitter data.
